import os
import json
from google import genai
from google.genai import types


def _make_client() -> genai.Client:
    """
    Initializes the Gemini API client using environment authentication.

    Returns:
        A genai.Client instance, or None if authentication is unavailable.
    """
    api_key = os.getenv("GEMINI_API_KEY")
    if not api_key or "dummy" in api_key.lower():
        # Triggers Mock Mode for deterministic behavior in keyless environments
        return None
    return genai.Client(api_key=api_key)


def _model_name() -> str:
    return os.getenv("GEMINI_MODEL", "gemini-2.0-flash")


class GeminiClient:
    """
    Thin wrapper around the Gemini API supporting multi-modal interaction.
    
    Provides specialized methods for both multi-turn technical assistance 
    and single-turn behavioral evaluation (the "Judge" role).
    """

    def __init__(self):
        self._client = _make_client()
        self._model = _model_name()
        self._is_mock = self._client is None

    def assistant_call(self, prompt: str, history: list[dict], system_prompt: str) -> str:
        """
        Executes a turns in the interactive coding assistant chat.

        Args:
            prompt: User-provided engineering query.
            history: List of prior turns to maintain conversation context.
            system_prompt: Base instructions defining the assistant's persona.

        Returns:
            The textual response generated by the model.
        """
        if self._is_mock:
            return "MOCK RESPONSE: I'm currently running in Fallback Mode without a valid Gemini API Key. To enable real AI suggestions, please provide a valid GEMINI_API_KEY in your .env file."

        gemini_history = [
            types.Content(
                role=msg["role"],
                parts=[types.Part(text=msg["content"])],
            )
            for msg in history
        ]

        chat = self._client.chats.create(
            model=self._model,
            config=types.GenerateContentConfig(system_instruction=system_prompt),
            history=gemini_history,
        )
        response = chat.send_message(prompt)
        return response.text

    def judge_call(self, user_prompt: str, system_prompt: str) -> str:
        """
        Produces a synthesized behavioral narrative for recruiters.

        Args:
            user_prompt: Substituted template containing calculated metrics and excerpts.
            system_prompt: Evaluation rubric used to standardize judge output.

        Returns:
            A professional narrative summary of the candidate's session.
        """
        if self._is_mock:
            return "MOCK NARRATIVE: The candidate's session was analyzed using heuristic fallbacks because no Gemini API key was provided. The resulting scores represent behavioral patterns detected via telemetry."

        response = self._client.models.generate_content(
            model=self._model,
            contents=user_prompt,
            config=types.GenerateContentConfig(system_instruction=system_prompt),
        )
        return response.text
